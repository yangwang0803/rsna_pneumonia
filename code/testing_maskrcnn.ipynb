{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from pneumonia import InferenceConfig, InferenceConfig2\n",
    "from functions import get_image_fps, box_locations, iou, create_submission, testing_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'stage_1_train_images')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'stage_2_test_images')\n",
    "\n",
    "MODEL_DIR = '../model/Mask_RCNN'\n",
    "ORIG_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join(MODEL_DIR))  # To find local version of the library\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_size= 1500\n"
     ]
    }
   ],
   "source": [
    "# Load validation file paths\n",
    "image_fps_val = pd.read_csv('image_fps_val.csv').image_fps_val.tolist()\n",
    "print('validation_size=', len(image_fps_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 prediction\n",
    "This phase predicts with original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        3\n",
      "DETECTION_MIN_CONFIDENCE       0.8\n",
      "DETECTION_NMS_THRESHOLD        0.1\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0, 'mrcnn_class_loss': 1.0, 'rpn_bbox_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               3\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           pneumonia\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                500\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               200\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Phase 1 config\n",
    "inference_config = InferenceConfig()\n",
    "inference_config.display()\n",
    "assert inference_config.NUM_CLASSES == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select trained model by the latest path\n",
    "# dir_names = next(os.walk(MODEL_DIR))[1]\n",
    "# key = inference_config.NAME.lower()\n",
    "# dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
    "# dir_names = sorted(dir_names)\n",
    "\n",
    "# if not dir_names:\n",
    "#     import errno\n",
    "#     raise FileNotFoundError(\n",
    "#         errno.ENOENT,\n",
    "#         \"Could not find model directory under {}\".format(self.model_dir))\n",
    "\n",
    "# fps = []\n",
    "# # Pick last directory\n",
    "# for d in dir_names: \n",
    "#     dir_name = os.path.join(MODEL_DIR, d)\n",
    "#     # Find the last checkpoint\n",
    "#     checkpoints = next(os.walk(dir_name))[2]\n",
    "#     checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
    "#     checkpoints = sorted(checkpoints)\n",
    "#     if not checkpoints:\n",
    "#         print('No weight files in {}'.format(dir_name))\n",
    "#     else:\n",
    "#         checkpoint = os.path.join(dir_name, checkpoints[-1])\n",
    "#         fps.append(checkpoint)\n",
    "\n",
    "# model_path = sorted(fps)[-1]\n",
    "# print('model_path=', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select phase 1 model\n",
    "model_path = '../model/Mask_RCNN/pneumonia20181018T1640/mask_rcnn_pneumonia_0020.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  ../model/Mask_RCNN/pneumonia20181018T1640/mask_rcnn_pneumonia_0020.h5\n",
      "Re-starting from epoch 20\n"
     ]
    }
   ],
   "source": [
    "# Load phase 1 trained model\n",
    "model = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 prediction\n",
    "def predict(image_fps, min_conf=0.95, augment=False):\n",
    "    RESIZE_FACTOR = ORIG_SIZE / inference_config.IMAGE_SHAPE[0]\n",
    "    prediction={}\n",
    "    \n",
    "    for image_id in tqdm(image_fps):\n",
    "        ds = pydicom.read_file(image_id)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        \n",
    "        image, window, scale, padding, crop = utils.resize_image(\n",
    "            image,\n",
    "            min_dim=inference_config.IMAGE_MIN_DIM,\n",
    "            min_scale=inference_config.IMAGE_MIN_SCALE,\n",
    "            max_dim=inference_config.IMAGE_MAX_DIM,\n",
    "            mode=inference_config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "        patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
    "        \n",
    "        # print(patient_id)\n",
    "        \n",
    "        r = model.detect([image])\n",
    "        r = r[0]\n",
    "        \n",
    "        # print(r['scores'])\n",
    "        # print('debug1=', len(r['scores']))\n",
    "        \n",
    "        if augment:\n",
    "            r2 = model.detect([np.fliplr(image)])\n",
    "            r2 = r2[0]\n",
    "            \n",
    "            # print(r2['scores'])\n",
    "            \n",
    "            r = testing_augment(r, r2, min_conf, inference_config)\n",
    "            \n",
    "        # print(len(r['rois']))\n",
    "        \n",
    "\n",
    "        if len(r['rois'])==0:\n",
    "            prediction[patient_id]=[]\n",
    "        else:\n",
    "            prediction[patient_id]=[]\n",
    "            \n",
    "            for i in range(len(r['rois'])):\n",
    "                if r['scores'][i] > min_conf:\n",
    "                    score = r['scores'][i]\n",
    "                    x = r['rois'][i][1]\n",
    "                    y = r['rois'][i][0]\n",
    "                    \n",
    "                    if x>0 and y>0:\n",
    "                        width = r['rois'][i][3] - x\n",
    "                        height = r['rois'][i][2] - y\n",
    "\n",
    "                        x*=RESIZE_FACTOR\n",
    "                        y*=RESIZE_FACTOR\n",
    "                        width*=RESIZE_FACTOR\n",
    "                        height*=RESIZE_FACTOR\n",
    "                    \n",
    "                        prediction[patient_id].append([score, x, y, width, height])\n",
    "                \n",
    "    return prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = box_locations()\n",
    "# prediction = predict(image_fps_val, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [06:05<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = predict(image_fps_val, min_conf=0.96, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19376230920728701 269 360 823 48\n"
     ]
    }
   ],
   "source": [
    "iou_all_mean,tp,fp,tn,fn = iou(truth, prediction)\n",
    "print(iou_all_mean,tp,fp,tn,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on all training data for training phase 2 model\n",
    "if False:\n",
    "    image_fps_train = get_image_fps(TRAIN_DIR)\n",
    "    prediction = predict(image_fps_train, min_conf=0.96, augment=True)\n",
    "    \n",
    "    # Convert prediction to training labels\n",
    "    train_labels_2 = pd.DataFrame(columns=['patientId', 'x', 'y', 'width', 'height', 'Target', 'class'])\n",
    "    i=0\n",
    "    for patient_id in list(prediction.keys()):\n",
    "\n",
    "        if len(truth[patient_id])>0:\n",
    "            for box in truth[patient_id]:\n",
    "                train_labels_2.loc[i] = [patient_id, int(box[0]), int(box[1]), int(box[2]), int(box[3]), 1, 1]\n",
    "                i+=1\n",
    "        else:\n",
    "            if len(prediction[patient_id])>0:\n",
    "                for box in prediction[patient_id]:\n",
    "                    train_labels_2.loc[i] = [patient_id, int(box[1]), int(box[2]), int(box[3]), int(box[4]), 0, 2]\n",
    "                    i+=1\n",
    "            else:\n",
    "                train_labels_2.loc[i] = [patient_id, np.nan, np.nan, np.nan, np.nan, 0, 0]\n",
    "                i+=1\n",
    "\n",
    "    train_labels_2.sort_values(by='patientId', inplace=True)\n",
    "    train_labels_2.to_csv(os.path.join(DATA_DIR, 'train_labels_2.csv'), index=False)\n",
    "    print(len(train_labels_2))\n",
    "    train_labels_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 prediction\n",
    "This phase predicts with pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        3\n",
      "DETECTION_MIN_CONFIDENCE       0.6\n",
      "DETECTION_NMS_THRESHOLD        0.1\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0, 'mrcnn_class_loss': 1.0, 'rpn_bbox_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               3\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           pneumonia\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                500\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               200\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Phase 2 config\n",
    "inference_config_2 = InferenceConfig2()\n",
    "inference_config_2.display()\n",
    "assert inference_config_2.NUM_CLASSES == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select phase 2 model\n",
    "model_2_path = '../model/Mask_RCNN/pneumonia20181021T0214/mask_rcnn_pneumonia_0020.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  ../model/Mask_RCNN/pneumonia20181021T0214/mask_rcnn_pneumonia_0020.h5\n",
      "Re-starting from epoch 20\n"
     ]
    }
   ],
   "source": [
    "# Load phase 2 trained model\n",
    "model_2 = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config_2,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_2_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_2_path)\n",
    "model_2.load_weights(model_2_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 prediction\n",
    "def predict2(image_fps, min_conf=0.90, augment=False):\n",
    "    RESIZE_FACTOR = ORIG_SIZE / inference_config_2.IMAGE_SHAPE[0]\n",
    "    prediction={}\n",
    "    \n",
    "    for image_id in tqdm(image_fps):\n",
    "        ds = pydicom.read_file(image_id)\n",
    "        image = ds.pixel_array\n",
    "        \n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        \n",
    "        image, window, scale, padding, crop = utils.resize_image(\n",
    "            image,\n",
    "            min_dim=inference_config.IMAGE_MIN_DIM,\n",
    "            min_scale=inference_config.IMAGE_MIN_SCALE,\n",
    "            max_dim=inference_config.IMAGE_MAX_DIM,\n",
    "            mode=inference_config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "        patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
    "        \n",
    "        # print(patient_id)\n",
    "        \n",
    "        r = model_2.detect([image])\n",
    "        r = r[0]\n",
    "        \n",
    "        # print(r['scores'])\n",
    "        # print('debug1=', len(r['scores']))\n",
    "        \n",
    "        if augment:\n",
    "            r2 = model_2.detect([np.fliplr(image)])\n",
    "            r2 = r2[0]\n",
    "            \n",
    "            #print(r2['scores'])\n",
    "            \n",
    "            r = testing_augment(r, r2, min_conf, inference_config)\n",
    "        \n",
    "\n",
    "        if len(r['rois'])==0:\n",
    "            prediction[patient_id]=[]\n",
    "        else:\n",
    "            prediction[patient_id]=[]\n",
    "            \n",
    "            for i in range(len(r['rois'])):\n",
    "                if r['class_ids'][i]==2 and r['scores'][i] > min_conf:\n",
    "                    score = r['scores'][i]\n",
    "                    x = r['rois'][i][1]\n",
    "                    y = r['rois'][i][0]\n",
    "                    \n",
    "                    if x>0 and y>0:\n",
    "                        width = r['rois'][i][3] - x\n",
    "                        height = r['rois'][i][2] - y\n",
    "\n",
    "                        x*=RESIZE_FACTOR\n",
    "                        y*=RESIZE_FACTOR\n",
    "                        width*=RESIZE_FACTOR\n",
    "                        height*=RESIZE_FACTOR\n",
    "                    \n",
    "                        prediction[patient_id].append([score, x, y, width, height])\n",
    "                \n",
    "    return prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:34<00:00,  6.99it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction_2 = predict2(image_fps_val, min_conf=0.92, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge predictions from two phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_predictions(prediction, prediction_2):\n",
    "    prediction_3 = copy.deepcopy(prediction)\n",
    "    \n",
    "    for patient_id in list(prediction_2.keys()):\n",
    "        if len(prediction_2[patient_id])>0:\n",
    "            prediction_3[patient_id] = []\n",
    "    \n",
    "    return prediction_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_3 = merge_predictions(prediction, prediction_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21805178140096618 248 235 948 69\n"
     ]
    }
   ],
   "source": [
    "iou_all_mean,tp,fp,tn,fn = iou(truth, prediction_3)\n",
    "print(iou_all_mean,tp,fp,tn,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [12:13<00:00,  4.19it/s]\n",
      "100%|██████████| 3000/3000 [07:09<00:00,  6.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict on testing data and create submission\n",
    "if True:\n",
    "    image_fps_test = get_image_fps(TEST_DIR)\n",
    "    image_fps_test.sort()\n",
    "\n",
    "    prediction_test = predict(image_fps_test, min_conf=0.96, augment=True)\n",
    "    prediction_test_2 = predict2(image_fps_test, min_conf=0.92, augment=False)\n",
    "    prediction_test_3 = merge_predictions(prediction_test, prediction_test_2)\n",
    "    \n",
    "    create_submission(prediction_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>0000a175-0e68-4ca4-b1af-167204a7e0bc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>0005d3cc-3c3f-40b9-93c3-46231c3eb813</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>000686d7-f4fc-448d-97a0-44fa9c5d3aa6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>000e3a7d-c0ca-4349-bb26-5af2d8993c3d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>00100a24-854d-423d-a092-edcf6179e061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>0015597f-2d69-4bc7-b642-5b5e01534676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>001b0c51-c7b3-45c1-9c17-fa7594cab96e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0022bb50-bf6c-4185-843e-403a9cc1ea80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>00271e8e-aea8-4f0a-8a34-3025831f1079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>0028450f-5b8e-4695-9416-8340b6f686b0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 patientId PredictionString\n",
       "2424  0000a175-0e68-4ca4-b1af-167204a7e0bc              NaN\n",
       "2543  0005d3cc-3c3f-40b9-93c3-46231c3eb813              NaN\n",
       "953   000686d7-f4fc-448d-97a0-44fa9c5d3aa6              NaN\n",
       "1835  000e3a7d-c0ca-4349-bb26-5af2d8993c3d              NaN\n",
       "1211  00100a24-854d-423d-a092-edcf6179e061              NaN\n",
       "2361  0015597f-2d69-4bc7-b642-5b5e01534676              NaN\n",
       "1937  001b0c51-c7b3-45c1-9c17-fa7594cab96e              NaN\n",
       "1015  0022bb50-bf6c-4185-843e-403a9cc1ea80              NaN\n",
       "1154  00271e8e-aea8-4f0a-8a34-3025831f1079              NaN\n",
       "1830  0028450f-5b8e-4695-9416-8340b6f686b0              NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission.csv')\n",
    "submission.sort_values(by='patientId').head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
