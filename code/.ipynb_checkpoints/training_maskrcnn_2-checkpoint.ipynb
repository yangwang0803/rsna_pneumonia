{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import glob \n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import pydicom\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'stage_1_train_images')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'stage_1_test_images')\n",
    "\n",
    "MODEL_DIR = '../model/Mask_RCNN'\n",
    "COCO_WEIGHTS_PATH = os.path.join(MODEL_DIR, 'mask_rcnn_coco.h5')\n",
    "ORIG_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join(MODEL_DIR))  # To find local version of the library\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pneumonia import PneumoniaDataset2, PneumoniaConfig2\n",
    "from functions import parse_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        3\n",
      "DETECTION_MIN_CONFIDENCE       0.8\n",
      "DETECTION_NMS_THRESHOLD        0.1\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'mrcnn_mask_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'rpn_class_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               3\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           pneumonia\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                500\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               200\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The following parameters have been selected to reduce running time for demonstration purposes \n",
    "# These are not optimal \n",
    "\n",
    "config = PneumoniaConfig2()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dataset\n",
    "annotations = pd.read_csv(os.path.join(DATA_DIR, 'stage_1_train_labels_2.csv'))\n",
    "image_fps, image_annotations = parse_dataset(TRAIN_DIR, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size= 24184\n",
      "validation_size= 1500\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training vs. validation dataset\n",
    "image_fps_train = pd.read_csv('image_fps_train.csv').image_fps_train.tolist()\n",
    "image_fps_val = pd.read_csv('image_fps_val.csv').image_fps_val.tolist()\n",
    "print('train_size=', len(image_fps_train))\n",
    "print('validation_size=', len(image_fps_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset\n",
    "dataset_train = PneumoniaDataset2(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Prepare the validation dataset\n",
    "dataset_val = PneumoniaDataset2(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation (light but constant)\n",
    "augmentation = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    \n",
    "    iaa.OneOf([ ## geometric transform\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.02)},\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
    "            rotate=(-2, 2),\n",
    "            shear=(-1, 1),\n",
    "        ),\n",
    "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
    "    ]),\n",
    "    \n",
    "    iaa.OneOf([ ## brightness or contrast\n",
    "        iaa.Multiply((0.9, 1.1)),\n",
    "        iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    ]),\n",
    "    \n",
    "    iaa.OneOf([ ## blur or sharpen\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Exclude the last layers because they require a matching\n",
    "# number of classes\n",
    "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
    "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "    \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.002\n",
      "\n",
      "Checkpoint Path: ../model/Mask_RCNN/pneumonia20181021T0214/mask_rcnn_pneumonia_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "workers= 1\n",
      "use_multiprodcessing= False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500/500 [==============================] - 668s 1s/step - loss: 1.7834 - rpn_class_loss: 0.0201 - rpn_bbox_loss: 0.4059 - mrcnn_class_loss: 0.4714 - mrcnn_bbox_loss: 0.4922 - mrcnn_mask_loss: 0.3937 - val_loss: 1.4994 - val_rpn_class_loss: 0.0143 - val_rpn_bbox_loss: 0.2679 - val_mrcnn_class_loss: 0.4655 - val_mrcnn_bbox_loss: 0.4084 - val_mrcnn_mask_loss: 0.3432\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 546s 1s/step - loss: 1.4610 - rpn_class_loss: 0.0130 - rpn_bbox_loss: 0.2916 - mrcnn_class_loss: 0.4323 - mrcnn_bbox_loss: 0.3773 - mrcnn_mask_loss: 0.3468 - val_loss: 1.4615 - val_rpn_class_loss: 0.0129 - val_rpn_bbox_loss: 0.3245 - val_mrcnn_class_loss: 0.4233 - val_mrcnn_bbox_loss: 0.3507 - val_mrcnn_mask_loss: 0.3501\n",
      "CPU times: user 53min 19s, sys: 34min 16s, total: 1h 27min 36s\n",
      "Wall time: 20min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "## train heads with higher lr to speedup the learning\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE*2,\n",
    "            epochs=2,\n",
    "            layers='heads',\n",
    "            augmentation=None)  ## no need to augment yet\n",
    "\n",
    "history = model.keras_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            epochs=6,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=LEARNING_RATE/5,\n",
    "#             epochs=14,\n",
    "#             layers='all',\n",
    "#             augmentation=augmentation)\n",
    "\n",
    "# new_history = model.keras_model.history.history\n",
    "# for k in new_history: history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=LEARNING_RATE/50,\n",
    "#             epochs=20,\n",
    "#             layers='all',\n",
    "#             augmentation=augmentation)\n",
    "\n",
    "# new_history = model.keras_model.history.history\n",
    "# for k in new_history: history[k] = history[k] + new_history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "epochs = range(1,len(next(iter(history.values())))+1)\n",
    "df_history = pd.DataFrame(history, index=epochs)\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(epochs, history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train class ce\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid class ce\")\n",
    "plt.legend()\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train box loss\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid box loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history[\"val_loss\"])\n",
    "print(\"Best Epoch:\", best_epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history.to_csv('df_history.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
